\subsection*{3.3\quad 机器学习基础}
\subsubsection*{3.3.1\quad 关键对象与术语}
\noindent \textbf{一\quad 任务 数据与样本\quad 基本对象与形式化表示}

\noindent 机器学习研究的直接对象是学习问题的形式化表达，而不是孤立的算法技巧。一个学习系统要成立，首先必须明确三件事。系统要完成的任务是什么，系统将从何种经验中改进，以及用何种性能度量来判定改进是否发生。任务给出输出的语义与形式，经验规定可用于学习的信息来源，性能度量则决定训练与比较模型时好坏的标尺。三者共同构成学习问题的边界条件。边界不清，训练过程即便收敛，也可能是在优化与真实目标不一致的替代目标。

\noindent 在形式化层面，最常用的表达是区分输入与输出。通常用 $X$ 表示输入数据，常见形式是特征矩阵或设计矩阵，用 $y$ 表示输出数据，也就是目标、标签或响应。$X$ 表示预测时可获得的描述信息，$y$ 表示训练阶段用作监督信号而在预测时不可直接使用的目标信息。以房价预测为例，$X$ 可以包含面积、户型、地段、楼龄、周边配套等属性，$y$ 是成交价格。训练阶段模型观察 $(X, y)$ 来学习映射规律。部署阶段模型仅接收新的 $X$，输出预测值 $\hat{y}$。这一区分看似只是符号约定，实质上规定了信息可得性的硬约束。任何预测时无法获得的信息，都不应被纳入 $X$。如果把未来信息或与目标几乎同义的字段混入特征，离线指标往往会异常乐观，而上线表现会迅速变差。

\noindent 在 $X$ 与 $y$ 的表示下，数据集由大量样本组成。样本是学习与评估的基本单位，通常对应 $X$ 的一行，也就是一个输入实例的特征向量。特征对应 $X$ 的一列，表示对所有样本以同一规则测量或抽取的属性。仍以房价为例，每套房子是一条样本，面积、卧室数、是否学区房是不同特征。将数据组织为矩阵并非为了形式美观，而是为了把异质对象统一成可计算的表示，从而使学习一个从 $X$ 到 $y$ 的映射成为明确的数学问题。

\noindent 监督学习中的标签应被视为一种观测结果，而不是天然真值。很多任务的标签来自人工标注、业务规则或延迟反馈，因此不可避免地包含噪声、口径不一致以及随时间变化的漂移。以垃圾信息识别为例，$X$ 可由邮件正文、标题、发件域名、历史交互等构成，$y$ 为垃圾或非垃圾。对于边界邮件，不同标注者或不同时期的策略可能给出不同结论。这类不一致会直接体现在模型可达到的上限与误差形态之中。因此，标签定义的清晰性、稳定性与可复现性，是模型性能与实验可信度的前置条件，而不是训练之后才考虑的附属问题。

\noindent 训练与评估的分离是学习问题成立的基本要求。用同一批数据既训练又评估，会把对已见样本的拟合误当作对未见样本的能力，从而得到系统性偏高的结论。实践中通常将数据划分为训练集、验证集与测试集。训练集用于拟合模型参数，验证集用于模型选择与超参数调节，测试集用于对最终模型给出尽可能无偏的泛化估计。需要强调的是，分离不仅发生在模型训练层面，也必须贯穿所有会从数据中估计统计量的步骤。以标准化为例，如果先用全量数据计算均值与方差再切分数据，测试集的信息已经通过统计量渗入训练过程。类似风险同样存在于缺失值填充、特征选择、降维、目标编码等预处理之中。可靠的流程是先切分，再在训练数据上拟合预处理参数，并把同样的变换仅应用到验证集与测试集上。

\noindent 此外，样本之间并不总是相互独立。现实数据常存在同源相关性，例如同一用户的多次行为、同一设备的连续监测窗口、同一患者的多次影像检查等。如果这些高度相关的样本同时出现在训练集与测试集，模型可能通过记住实体特征取得高分，而在真正的新实体上表现明显下降。以医疗影像为例，如果同一患者的多张 X 光片分散到训练与测试中，模型可能利用与病灶无关但与患者个体相关的低层纹理或成像条件获得虚高的测试成绩。因而，数据划分策略应与泛化目标一致。当目标是对新用户、新设备或新时间段泛化时，划分就应避免相关样本跨集合混入，从评估机制上保证测试集确实代表未见条件。

\noindent 通过上述概念体系，学习问题获得了统一而严格的表述。用 $X$ 描述可用输入，用 $y$ 定义监督目标，以样本与特征的矩阵结构组织数据，并通过训练、验证、测试的隔离流程约束评估可信度，同时在必要时显式处理样本相关结构对泛化判断的影响。后续关于模型、损失函数与优化方法的讨论，均以这些基本对象与表示为基础展开。

\noindent \textbf{二\quad 模型、假设空间、参数与超参数}

\noindent 为使概念精确且便于落地，本节使用同一例子贯穿，用线性模型预测房价。设输入为特征向量 $x \in \mathbb{R}^d$，输出为真实价格 $y \in \mathbb{R}$。训练数据集记为
$\mathcal{D}=\{(x_i,y_i)\}_{i=1}^n$。

\noindent \textbf{1）模型}

\noindent 在机器学习语境中，模型更准确地指一族参数化函数，用来近似真实但未知的映射关系。在线性回归中，我们选用如下参数化形式
$\hat{y}=f(x;\theta)=w^\top x + b$，
其中 $w\in\mathbb{R}^d$ 为权重向量，$b\in\mathbb{R}$ 为偏置，$\theta=(w,b)$ 为模型参数集合。

\noindent 这一表达式的关键不在于给出某个具体预测值，而在于规定了预测函数必须属于仿射函数这一类。换言之，模型在此阶段只是定义了允许的函数形态，即线性叠加，而具体形态由参数决定。模型形式一旦确定，后续训练与评估都在这一形式的约束下展开。

\noindent 线性是相对于特征表示 $x$ 而言的。若对原始变量做非线性变换并将其作为新特征，例如 $\log(\text{距离})$、$\text{面积}^2$、$\text{面积}\times\text{学区}$ 等，模型仍保持对特征向量 $x$ 的线性，但在原始变量上可表现为非线性。因此，模型表达能力并非只由公式是否线性决定，还取决于特征表示的构造方式。严格地说，模型形式与特征表示共同决定了可表达的函数集合。

\noindent \textbf{2）表示与归纳偏置}

\noindent 任何学习算法都不可能在所有可能函数上有效搜索，因此必须通过模型形式与特征表示引入结构性约束。这种约束可视为归纳偏置，即在观察有限样本后，我们倾向于选择哪类函数作为解释数据的规律。

\noindent 在线性模型中，归纳偏置体现在，在给定表示 $x$ 下，输出随特征变化呈线性叠加，模型倾向于用各特征的加权贡献解释预测。这种偏置带来的直接后果是，当真实关系接近线性或可由合适特征变换线性化时，线性模型在样本较少、噪声存在的情况下往往更稳定。当真实关系强非线性且特征表示不足时，线性模型会出现系统性偏差，表现为欠拟合。

\noindent 归纳偏置并非主观任性，而是学习可行性的必要条件。如果不通过某种方式限制候选函数集合，就无法在有限数据下形成可推广的结论。

\noindent \textbf{3）假设与假设空间}

\noindent 在学习理论中，假设指某个候选预测函数，假设空间指学习算法允许选择的全部候选函数集合。对于线性模型
$\mathcal{H}=\{h_{w,b}(x)=w^\top x+b \mid w\in\mathbb{R}^d,\, b\in\mathbb{R}\}$。
这里每一组 $(w,b)$ 都定义了一个具体假设 $h_{w,b}$，而 $\mathcal{H}$ 是所有这类仿射函数的集合。

\noindent 这一形式化描述的意义在于，训练并不是创造一个函数，而是在 $\mathcal{H}$ 中选择一个函数。假设空间的大小与结构直接影响两类能力。一是可逼近能力，即是否包含足够接近真实规律的函数。二是可泛化能力，即在有限样本下是否容易被噪声误导。当 $\mathcal{H}$ 过小，模型即使训练充分也难以拟合主要规律。当 $\mathcal{H}$ 过大，模型可能在训练集上拟合得过好而对新样本不稳定。

\noindent 在线性模型里，$\mathcal{H}$ 的规模最直观地受特征维度 $d$ 影响。加入更多特征等价于扩大参数维度，进而扩大候选函数集合。但规模并不只等同于参数数量，还与特征之间的相关性、数据噪声、以及后续引入的约束如正则化共同决定。

\noindent \textbf{4）参数}

\noindent 参数是由训练过程直接从数据中估计的量。在线性模型中，参数就是 $(w,b)$。训练的目标是在给定数据集 $\mathcal{D}$ 与某个训练准则下，选出最合适的参数，从而确定最终使用的具体假设 $h_{w,b}$。

\noindent 为了把参数学习说得严谨，需要明确训练准则。以最常用的平方损失为例，经验风险为
$\hat{R}(w,b)=\frac{1}{n}\sum_{i=1}^n (y_i-(w^\top x_i+b))^2$。
参数学习就是求解
$(w^\ast,b^\ast)=\arg\min_{w,b}\ \hat{R}(w,b)$。
在此框架下，$(w^\ast,b^\ast)$ 是由数据驱动的结果，数据改变，最优参数一般也会改变。由此可以看到，参数的本质是，在既定的函数族与训练准则下，对具体函数进行实例化的自由度。

\noindent 参数还承担解释性角色。在不发生严重共线性且特征尺度可比的前提下，$w_j$ 反映了第 $j$ 个特征对预测的边际影响方向与强度。然而在实际数据中，特征相关性、尺度差异、以及特征工程引入的交互项常使单个权重的因果解释不成立，因此需要区分预测贡献意义与因果效应意义。

\noindent \textbf{5）超参数}

\noindent 超参数是不在一次参数拟合过程中由数据直接估计得到，而是由建模者预先设定或通过外层搜索选择的量。它们通常分为两类，结构性超参数与约束及过程性超参数。线性模型提供了非常清晰的例子。

\noindent \textbf{（1）约束性超参数：正则化强度 $\lambda$}

\noindent 在有限样本与噪声存在时，仅最小化经验风险可能导致模型对训练数据的偶然波动过度敏感。为控制有效复杂度，常在目标中加入正则项，得到正则化经验风险
$\hat{R}_\lambda(w,b)=\frac{1}{n}\sum_{i=1}^n (y_i-(w^\top x_i+b))^2+\lambda\Omega(w)$。
若取 $\Omega(w)=\|w\|_2^2$ 即岭回归，则
$(w^\ast_\lambda,b^\ast_\lambda)=\arg\min_{w,b}\ \frac{1}{n}\sum_{i=1}^n (y_i-(w^\top x_i+b))^2+\lambda\|w\|_2^2$。
此处 $\lambda\ge 0$ 就是典型超参数。它不属于模型参数向量 $(w,b)$，但它改变了优化问题本身，从而改变最终解的性质。直观上，$\lambda$ 越大，对大权重惩罚越强，模型被迫更平滑，对单个特征的极端依赖更少。$\lambda$ 越小，模型更强调拟合训练误差。严格地说，$\lambda$ 控制了解的偏差与方差权衡，增大 $\lambda$ 往往提高偏差、降低方差，反之亦然。

\noindent 需要强调，$\lambda$ 并不会在一次拟合过程中自动学出来。改变 $\lambda$ 通常意味着改变学习问题的定义，因此必须重新训练得到新的 $(w^\ast_\lambda,b^\ast_\lambda)$。这也是其作为超参数的决定性特征。

\noindent \textbf{（2）结构性超参数：特征扩展的阶数或规则}

\noindent 仍保持模型形式 $\hat{y}=w^\top x+b$，如果我们对原始输入做特征扩展，例如加入多项式项与交互项，则等价于改变输入表示 $\phi(\cdot)$，使用
$\hat{y}=w^\top \phi(x)+b$。
这里 $\phi(x)$ 的构造规则，例如扩展到几阶、多大范围的交互项、是否包含某些领域特征，决定了特征维度与表示能力，从而改变了假设空间
$\mathcal{H}_\phi=\{h_{w,b}(x)=w^\top \phi(x)+b\}$。
扩展阶数 $M$ 或特征生成规则不是通过一次训练直接估计得到的，它是对候选函数集合边界的设定，因此属于结构性超参数。$M$ 越大，$\phi(x)$ 越丰富，$\mathcal{H}_\phi$ 越大，表达能力增强，但在有限样本下过拟合风险也随之上升。反之，$M$ 太小则可能无法表达关键非线性结构。

\noindent \textbf{（3）训练过程超参数：学习率、迭代轮数与停止准则}

\noindent 即便在线性模型中，尤其采用迭代优化而非闭式解时，学习率、迭代步数、停止阈值等也属于超参数。它们不改变假设空间的定义，但会影响优化路径与收敛质量。学习率过大可能不收敛，过小则收敛缓慢并可能停在次优区域。停止策略则影响拟合到什么程度，从而间接影响泛化表现。

\noindent 综上，在线性模型这一例子里，参数 $(w,b)$ 是训练要直接估计的对象。超参数如 $\lambda$、特征扩展规则、学习率等，则决定了模型容量与训练机制。二者在职责上严格分离。参数学习回答在既定学习问题下取哪个具体函数，超参数选择回答学习问题该如何定义才更有利于泛化。

\noindent \textbf{三\quad 损失函数、目标函数与优化：训练到底在做什么}

\noindent 仍以房价预测为贯穿例子。设输入特征向量 $x \in \mathbb{R}^d$，真实价格 $y \in \mathbb{R}$。训练数据为
$\mathcal{D}=\{(x_i,y_i)\}_{i=1}^n$。
可以把它理解为 $n$ 条历史成交记录，每条记录是一套房子的信息与成交价配对样本。

\noindent \textbf{1）损失函数：把预测误差定义成一个可计算的数}

\noindent 损失函数衡量单个样本上的预测误差
$\ell\big(y,\hat{y}\big)=\ell\big(y,f(x;\theta)\big)$。
其作用是把预测和真实差多少压缩成一个数值，使训练过程能够据此比较不同参数下的好坏。

\noindent 回归任务中最常用的是平方损失
$\ell_{\text{sq}}(y,\hat{y})=(y-\hat{y})^2$。
误差越大，惩罚增长越快，平方会放大大误差，因此模型会倾向避免出现特别离谱的预测。

\noindent 另一个常见选择是绝对损失
$\ell_{1}(y,\hat{y})=\lvert y-\hat{y}\rvert$。
它对异常值更鲁棒，但目标函数不如平方损失平滑，优化实现通常更复杂。

\noindent \textbf{2）经验风险与目标函数：训练在最小化什么}

\noindent 训练的基本策略是让模型在训练集上的平均损失尽可能小。平均损失称为经验风险
$\hat{R}(\theta)=\frac{1}{n}\sum_{i=1}^n \ell\big(y_i,f(x_i;\theta)\big)$。
可以把它看成把每条样本的误差打分汇总后取平均，平均分越低，说明整体拟合越好。

\noindent 在本例中采用线性模型
$f(x;\theta)=w^\top x+b$，
并使用平方损失，则经验风险写为
$\hat{R}(w,b)=\frac{1}{n}\sum_{i=1}^n \big(y_i-(w^\top x_i+b)\big)^2$。
每套房子的误差是真实价减预测价，平方后求平均即得到训练集上的整体拟合误差。

\noindent 因此，训练对应一个明确的优化问题
$(w^\ast,b^\ast)=\arg\min_{w,b}\ \hat{R}(w,b)$。
训练完成后输出的是一组参数 $(w^\ast,b^\ast)$，也就是在训练集上使平均误差最小的那条线性预测规则。

\noindent \textbf{3）正则化：为什么目标函数常常不止拟合误差一项}

\noindent 若只追求训练误差最小，有限样本下容易过拟合。模型可能把训练数据中的偶然波动也当成规律。为提升稳定性，常在目标函数中加入正则项
$J(\theta)=\hat{R}(\theta)+\lambda\Omega(\theta)$。
这意味着训练不仅要求误差小，还要求模型不要过于复杂或极端。$\lambda$ 控制两者的权衡，$\lambda$ 越大越强调简单稳健，$\lambda$ 越小越强调贴合训练数据。

\noindent 岭回归即 L2 正则是回归中最常见的形式之一
$J(w,b)=\frac{1}{n}\sum_{i=1}^n \big(y_i-(w^\top x_i+b)\big)^2+\lambda\|w\|_2^2$。
$\|w\|_2^2$ 可理解为对权重总体规模的惩罚，它会抑制权重变得过大，从而减少模型对少数特征的过度依赖，使预测更稳定。

\noindent Lasso 即 L1 正则则写为
$J(w,b)=\frac{1}{n}\sum_{i=1}^n \big(y_i-(w^\top x_i+b)\big)^2+\lambda\|w\|_1$。
$\|w\|_1$ 倾向产生稀疏权重，很多权重变为 0，相当于自动筛掉部分特征，同时也意味着优化问题更不平滑，实现上更讲究技巧。

\noindent \textbf{4）优化：目标函数确定后，参数如何被求出来}

\noindent 目标函数 $J(\theta)$ 确定后，训练就变成数值优化，在参数空间中寻找使 $J(\theta)$ 最小的点。在线性回归加平方损失的场景下，该问题性质良好，既可以用闭式解，也可以用迭代法。在大规模训练中，迭代法更常用。

\noindent \textbf{（1）梯度下降：沿着下降最快的方向迭代}

\noindent 当 $J(\theta)$ 可微时，梯度 $\nabla_\theta J(\theta)$ 表示目标函数增大最快的方向，因此更新时取反方向
$\theta_{t+1}=\theta_t-\eta \nabla_\theta J(\theta_t)$。
每一步都沿着让目标变小最快的方向走一小步。学习率 $\eta$ 决定步长，过大可能震荡甚至发散，过小会收敛很慢。

\noindent 为看清更新在纠正什么，先定义残差
$r_i = y_i-(w^\top x_i+b)$。
它就是第 $i$ 个样本真实值减预测值的误差，正值表示预测偏低，负值表示预测偏高。

\noindent 在平方损失下，经验风险对参数的梯度为
$\nabla_w \hat{R}(w,b)=-\frac{2}{n}\sum_{i=1}^n r_i x_i,\quad
\frac{\partial \hat{R}(w,b)}{\partial b}=-\frac{2}{n}\sum_{i=1}^n r_i$。
权重 $w$ 的更新由残差与特征的相关性驱动，某个特征在系统性低估或高估时更相关，它对应的权重就会被相应上调或下调。偏置 $b$ 则根据整体残差的平均方向调整，总体低估就上调 $b$，总体高估就下调 $b$。

\noindent 若加入岭正则 $\lambda\|w\|_2^2$，梯度变为
$\nabla_w J(w,b)=-\frac{2}{n}\sum_{i=1}^n r_i x_i + 2\lambda w,\quad
\frac{\partial J(w,b)}{\partial b}=-\frac{2}{n}\sum_{i=1}^n r_i$。
额外项 $2\lambda w$ 会持续把权重往 0 拉回，从而抑制权重膨胀，提升模型稳定性。

\noindent \textbf{（2）批量、随机与小批量：每次用多少数据算梯度}

\noindent 批量梯度下降每次用全部 $n$ 条样本计算梯度，方向稳定，但单步计算开销大。随机梯度下降每次用 1 条样本近似梯度，更新频繁、单步很快，但方向噪声大，对学习率更敏感。小批量梯度下降每次用一小批样本，如 32 或 128，估计梯度，在速度与稳定性之间折中，是工程实践最常用的方式。

\noindent \textbf{5）学习率与停止：训练为何会跑偏或停得不合适}

\noindent 学习率 $\eta$ 决定每次纠错的力度。若 $\eta$ 过大，可能出现目标值震荡甚至上升，若过小，训练会极慢且在有限算力下难以达到足够好的解。实践中常配合学习率衰减、动量或自适应学习率方法以提高效率和稳定性。

\noindent 停止准则决定训练何时结束。对线性回归这类问题，可以用目标函数下降幅度很小或梯度足够小作为收敛信号。在更一般的学习任务中，还应结合验证集，当训练误差继续下降而验证误差不再下降甚至上升时，通常意味着过拟合正在发生，应考虑早停或增强正则化。

\noindent \textbf{四\quad 训练、验证与测试：为什么必须拆分数据}

\noindent 仍以房价预测为例。设数据集 $\mathcal{D}=\{(x_i,y_i)\}_{i=1}^n$，模型为 $\hat{y}=f(x;\theta)$，损失函数为 $\ell(y,\hat{y})$。上一节指出，训练阶段最小化的是训练数据上的平均损失即经验风险
$\hat{R}_{\mathcal{D}}(\theta)=\frac{1}{|\mathcal{D}|}\sum_{(x,y)\in \mathcal{D}}\ell\big(y,f(x;\theta)\big)$。
这一量反映的是模型对已见样本的拟合程度，但不能直接保证模型对未见样本同样可靠。训练、验证与测试的划分，正是为了解决拟合与泛化之间的天然张力。

\noindent \textbf{1）从训练误差到泛化误差：评估对象必须与目标一致}

\noindent 机器学习最终关心的是模型在未来数据上的表现，而不是在训练集上的表现。理想情况下，我们希望最小化真实数据分布 $P(x,y)$ 下的期望风险即泛化误差
$R(\theta)=\mathbb{E}_{(x,y)\sim P}\big[\ell\big(y,f(x;\theta)\big)\big]$。
由于 $P$ 不可直接获得，只能用样本近似。数据拆分的本质作用在于，用一份不参与训练的数据来近似评估 $R(\theta)$，并把这种评估结果用于模型选择与结论报告，从而避免训练误差下降被误读为未来表现变好。

\noindent \textbf{2）训练集、验证集与测试集：三种数据、三条不可混淆的职责}

\noindent 将数据拆分为互不重叠的三部分
$\mathcal{D}=\mathcal{D}_{\text{train}}\ \cup\ \mathcal{D}_{\text{val}}\ \cup\ \mathcal{D}_{\text{test}},\quad \text{两两不交}$。
更重要的是三者的权限边界，即哪一份数据可以影响哪些决策。

\noindent 训练集只负责学习参数 $\theta$，用于拟合模型参数
$\theta^\ast=\arg\min_{\theta}\ \hat{R}_{\mathcal{D}_{\text{train}}}(\theta)$。
训练集是唯一允许参与学习的数据。凡是被模型或预处理流程从数据中估计出来的内容，都必须限定在训练集内部完成。典型例子包括标准化所需的均值与方差、缺失值填充的统计量、类别编码映射、降维变换、特征选择规则等。原因并不复杂，这些步骤会改变输入表示或目标函数，从而影响最终学到的参数。它们一旦吸收了验证或测试的信息，就等价于把未见数据提前泄露给了训练过程。

\noindent 验证集只负责模型选择与调参。验证集不用于拟合参数，而用于在多种候选方案之间做选择。设超参数为 $\lambda$，例如正则化强度、特征扩展阶数、学习率策略等，通常流程是对每个候选 $\lambda$，先在训练集上训练得到 $\theta^\ast(\lambda)$，再在验证集上评估
$\lambda^\ast=\arg\min_{\lambda}\ \hat{R}_{\mathcal{D}_{\text{val}}}\big(\theta^\ast(\lambda)\big)$。
验证集的地位可以理解为外层裁判，它不参与学习，但决定学哪一种。在房价预测中，这对应一系列真实决策，正则化强度应取多大、是否加入某类交互特征、训练轮数与早停如何设置、采用 MAE 还是 RMSE 作为主要优化目标等。只要某个选择会影响最终模型形态，就应当由验证集或交叉验证来支撑，而不是由测试集来支撑。

\noindent 验证集还承担诊断功能。当训练误差持续下降而验证误差不再下降甚至上升时，通常意味着模型开始捕捉训练集中的偶然波动，泛化能力下降。此时应当调整模型复杂度、正则化或特征方案，而不是继续把训练误差压到更低。

\noindent 测试集只负责最终一次性报告，用于在模型方案确定之后做最终评估
$\widehat{\text{Perf}}=\text{Eval}\big(f(\cdot;\theta^\ast(\lambda^\ast)),\ \mathcal{D}_{\text{test}}\big)$。
测试集的关键原则是只评估，不决策。它不应参与任何选择过程，包括但不限于选择超参数、选择特征方案、比较不同模型、决定是否继续训练、决定是否更换损失函数或指标等。一旦测试集被用于反复试错，它就不再代表未见数据，评估结果会系统性偏乐观，最终导致对真实部署效果的错误预期。

\noindent \textbf{3）为什么不能用测试集调参：避免评估偏差与隐性过拟合}

\noindent 模型开发往往是迭代式的，你会反复尝试不同特征、不同正则、不同训练策略。若每次迭代都查看测试集表现并据此决定下一步方向，那么测试集事实上被纳入了模型选择过程，相当于对测试集进行外层拟合。结果是隐性过拟合，最终选出的方案可能只是对这份测试集适配得更好，并不保证对未来数据同样有效。

\noindent 因此，测试集应被视为事后检验。当且仅当你已经用训练集完成参数学习、用验证集完成模型选择之后，才用测试集给出一次性结论。这个结论才具有可复现性与解释力。

\noindent \textbf{4）交叉验证：用重复评估换取更稳定的模型选择}

\noindent 当数据量较小、样本波动较大，单次训练与验证划分可能带来较大的评估方差，模型选择容易受恰好怎么划分的影响。交叉验证通过多次划分与重复训练评估降低这种偶然性。以 $K$ 折交叉验证为例，将数据拆为 $K$ 份，每次取一份作为验证，其余作为训练，对同一超参数 $\lambda$ 得到 $K$ 个验证误差并求平均
$\widehat{R}_{\text{CV}}(\lambda)=\frac{1}{K}\sum_{k=1}^{K}\ \hat{R}_{\mathcal{D}^{(k)}}\big(\theta^{\ast(k)}(\lambda)\big)$。
交叉验证的直接收益是，模型优劣不再依赖单次划分的运气，而是由多次划分下的平均表现决定，从而更接近稳定的泛化估计。需要强调的是，交叉验证用于替代或增强验证集的角色，而不是替代测试集，测试集仍应保留为最终一次性评估。

\noindent \textbf{5）损失函数与评估指标：训练最小化的与业务关心的未必一致}

\noindent 训练时最小化的是损失函数构成的目标
$\min_{\theta}\ \hat{R}_{\mathcal{D}_{\text{train}}}(\theta)\quad \text{或 }+\lambda\Omega(\theta)$。
评估时关注的往往是业务可解释的指标，例如 MAE、RMSE、$R^2$，或在某个误差阈值内的命中率等。损失函数强调可优化性与训练稳定性，评估指标强调业务含义与决策相关性。二者可以不完全一致，但必须在设计上对齐。若训练目标与评估指标长期背离，模型可能训练得越来越好，但实际业务效果并不会同步改善。

\subsubsection*{3.3.2\quad 监督学习}
\subsubsection*{3.3.3\quad 无监督学习}
\subsubsection*{3.3.4\quad 强化学习}
\subsubsection*{3.3.5\quad 模型训练与评估}
\subsubsection*{3.3.6\quad 常用算法概览}
\paragraph{3.3.6.1\quad 回归方法}
\paragraph{3.3.6.2\quad 分类方法}
\paragraph{3.3.6.3\quad 聚类方法}
